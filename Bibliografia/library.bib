Automatically generated by Mendeley Desktop 1.11
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Yazdani2012,
author = {Yazdani, Reza and {Johari Majd}, Vahid and Oftadeh, Reza},
doi = {10.1109/IranianCEE.2012.6292471},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yazdani, Johari Majd, Oftadeh - 2012 - Dynamically stable trajectory planning for a quadruped robot.pdf:pdf},
isbn = {978-1-4673-1148-9},
journal = {20th Iranian Conference on Electrical Engineering (ICEE2012)},
keywords = {legged robot,locomotion,quadruped,stability,trajectory planning},
month = may,
pages = {845--850},
publisher = {Ieee},
title = {{Dynamically stable trajectory planning for a quadruped robot}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6292471},
year = {2012}
}
@phdthesis{Lojo2009,
author = {Lojo, Ignacio Pedrosa},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lojo - 2009 - Proyecto MIRHO (Mobile Intelligent Hexapod Robot).pdf:pdf},
school = {Universitat Polit\'{e}cnica de Catalunya},
title = {{Proyecto MIRHO (Mobile Intelligent Hexapod Robot)}},
url = {http://upcommons.upc.edu/handle/2099.1/6488},
year = {2009}
}
@article{Laue2006a,
author = {Laue, Tim and Spiess, Kai and R\"{o}fer, T},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Laue, Spiess, R\"{o}fer - 2006 - SimRobot–a general physical robot simulator and its application in robocup.pdf:pdf},
journal = {RoboCup 2005: Robot Soccer World Cup IX},
pages = {173--183},
title = {{SimRobot–a general physical robot simulator and its application in robocup}},
url = {http://link.springer.com/chapter/10.1007/11780519\_16},
year = {2006}
}
@article{Ruckert2012,
abstract = {BIOLOGICAL MOVEMENT GENERATION COMBINES THREE INTERESTING ASPECTS: its modular organization in movement primitives (MPs), its characteristics of stochastic optimality under perturbations, and its efficiency in terms of learning. A common approach to motor skill learning is to endow the primitives with dynamical systems. Here, the parameters of the primitive indirectly define the shape of a reference trajectory. We propose an alternative MP representation based on probabilistic inference in learned graphical models with new and interesting properties that complies with salient features of biological movement control. Instead of endowing the primitives with dynamical systems, we propose to endow MPs with an intrinsic probabilistic planning system, integrating the power of stochastic optimal control (SOC) methods within a MP. The parameterization of the primitive is a graphical model that represents the dynamics and intrinsic cost function such that inference in this graphical model yields the control policy. We parameterize the intrinsic cost function using task-relevant features, such as the importance of passing through certain via-points. The system dynamics as well as intrinsic cost function parameters are learned in a reinforcement learning (RL) setting. We evaluate our approach on a complex 4-link balancing task. Our experiments show that our movement representation facilitates learning significantly and leads to better generalization to new task settings without re-learning.},
author = {R\"{u}ckert, Elmar a and Neumann, Gerhard and Toussaint, Marc and Maass, Wolfgang},
doi = {10.3389/fncom.2012.00097},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/R\"{u}ckert et al. - 2012 - Learned graphical models for probabilistic planning provide a new class of movement primitives.pdf:pdf},
issn = {1662-5188},
journal = {Frontiers in computational neuroscience},
keywords = {graphical models,motor planning,movement primitives,movement primitives, motor planning, reinforcement,optimal control,reinforcement learning},
month = jan,
number = {January},
pages = {97},
pmid = {23293598},
title = {{Learned graphical models for probabilistic planning provide a new class of movement primitives.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3534186\&tool=pmcentrez\&rendertype=abstract},
volume = {6},
year = {2012}
}
@article{Quigley,
author = {Quigley, Morgan and Gerkey, Brian and Conley, Ken and Faust, Josh and Foote, Tully and Leibs, Jeremy and Berger, Eric and Wheeler, Rob and Ng, Andrew},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Quigley et al. - 2009 - ROS an open-source Robot Operating System.pdf:pdf},
journal = {ICRA Workshop on Open Source Software},
keywords = {middleware open robot ros source},
title = {{ROS: an open-source Robot Operating System}},
year = {2009}
}
@article{Purushotham2009,
author = {Purushotham, A. and Rao, G. Venkata},
journal = {International Journal of Applied Engineering Research},
title = {{Dynamic stability analysis of a quadruped robotic manipulator system: analytical approach.}},
year = {2009}
}
@phdthesis{Laud2004,
author = {Laud, Adam Daniel},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Laud - 2004 - THEORY AND APPLICATION OF REWARD SHAPING IN REINFORCEMENT LEARNING.pdf:pdf},
school = {University of Illinois at Urbana-Champaign},
title = {{Theory and Application of Reward Shaping in Reinforcement Learning}},
url = {https://www.ideals.illinois.edu/bitstream/handle/2142/10797/Theory and Application of Reward Shaping in Reinforcement Learning.pdf?sequence=2},
year = {2004}
}
@article{Sanchez2009,
author = {S\'{a}nchez, T Gonz\'{a}lez},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/S\'{a}nchez - 2009 - Artificial Vision in the Nao Humanoid Robot.pdf:pdf},
number = {September},
title = {{Artificial Vision in the Nao Humanoid Robot}},
url = {http://upcommons.upc.edu/handle/2099.1/7722},
year = {2009}
}
@article{Loc2011,
author = {Loc, Vo-Gia and Koo, Ig Mo and Tran, Duc Trong and Park, Sangdoek and Moon, Hyungpil and Choi, Hyouk Ryeol},
doi = {10.1016/j.robot.2011.08.007},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Loc et al. - 2011 - Improving traversability of quadruped walking robots using body movement in 3D rough terrains.pdf:pdf},
issn = {09218890},
journal = {Robotics and Autonomous Systems},
month = dec,
number = {12},
pages = {1036--1048},
publisher = {Elsevier B.V.},
title = {{Improving traversability of quadruped walking robots using body movement in 3D rough terrains}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0921889011001588},
volume = {59},
year = {2011}
}
@article{Hornby1999,
author = {Hornby, GS and Fujita, Masahiro and Takamura, S},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hornby, Fujita, Takamura - 1999 - Autonomous evolution of gaits with the sony quadruped robot.pdf:pdf},
journal = {\ldots and Evolutionary \ldots},
title = {{Autonomous evolution of gaits with the sony quadruped robot}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.153.1722\&rep=rep1\&type=pdf},
year = {1999}
}
@article{Kaelbling1996,
author = {Kaelbling, LP and Littman, ML and Moore, AW},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kaelbling, Littman, Moore - 1996 - Reinforcement learning A survey.pdf:pdf},
journal = {arXiv preprint cs/9605103},
pages = {237--285},
title = {{Reinforcement learning: A survey}},
url = {http://arxiv.org/abs/cs/9605103},
volume = {4},
year = {1996}
}
@article{Kalakrishnan2010,
author = {Kalakrishnan, M. and Buchli, J. and Pastor, P. and Mistry, M. and Schaal, S.},
doi = {10.1177/0278364910388677},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kalakrishnan et al. - 2010 - Learning, planning, and control for quadruped locomotion over challenging terrain.pdf:pdf},
issn = {0278-3649},
journal = {The International Journal of Robotics Research},
keywords = {floating base inverse,locomotion planning and control,quadruped locomotion,template learning,zmp optimization},
month = nov,
number = {2},
pages = {236--258},
title = {{Learning, planning, and control for quadruped locomotion over challenging terrain}},
url = {http://ijr.sagepub.com/cgi/doi/10.1177/0278364910388677},
volume = {30},
year = {2010}
}
@article{Torrent-Fontbona2013,
abstract = {Immobile Location-Allocation (ILA) is a combinatorial problem which consists in, given a set of facilities and a set of demand points, determining the optimal service each facility has to offer and allocating the demand to such facilities. The applicability of optimization methods is tied up to the dimensionality of the problem, but since the distance between data points is a key factor, clustering techniques to partition the data space can be applied, converting the large initial problem into several simpler ILA problems that can be solved separately. This paper presents a novel method that combines clustering and heuristic methods to solve an ILA problem, which reduces the elapsed time keeping the quality of the solution found compared with other heuristics methods. © 2013 Elsevier Ltd. All rights reserved.},
author = {Torrent-Fontbona, F. and Mu\~{n}oz, V. and L\'{o}pez, B.},
doi = {10.1016/j.eswa.2013.01.065},
isbn = {0957-4174},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Affinity propagation,Clustering,Heuristics,Immobile location-Allocation,Simulated annealing},
pages = {4593--4599},
title = {{Solving large immobile location-Allocation by affinity propagation and simulated annealing. Application to select which sporting event to watch}},
volume = {40},
year = {2013}
}
@article{Santos2012,
author = {Santos, Cristina P. and Matos, V\'{\i}tor},
doi = {10.1016/j.robot.2012.01.004},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Santos, Matos - 2012 - CPG modulation for navigation and omnidirectional quadruped locomotion.pdf:pdf},
issn = {09218890},
journal = {Robotics and Autonomous Systems},
month = jun,
number = {6},
pages = {912--927},
publisher = {Elsevier B.V.},
title = {{CPG modulation for navigation and omnidirectional quadruped locomotion}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0921889012000164},
volume = {60},
year = {2012}
}
@article{Taylor2009,
abstract = {The reinforcement learning paradigm is a popular way to address problems that have only limited environmental feedback, rather than correctly labeled examples, as is common in other machine learning contexts. While significant progress has been made to improve learning in a single task, the idea of transfer learning has only recently been applied to reinforcement learning tasks. The core idea of transfer is that experience gained in learning to perform one task can help improve learning performance in a related, but different, task. In this article we present a framework that classifies transfer learning methods in terms of their capabilities and goals, and then use it to survey the existing literature, as well as to suggest future directions for transfer learning work.},
author = {Taylor, Matthew E and Stone, Peter},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Taylor, Stone - 2009 - Transfer Learning for Reinforcement Learning Domains A Survey.pdf:pdf},
isbn = {15324435},
issn = {15324435},
journal = {Journal of Machine Learning Research},
keywords = {1,1998,actions with goal,example,leaning agents take sequential,maximizing a reward,multi task learning,problems,reinforcement learning,rl,signal,sutton barto,transfer learning,transfer learning objectives,which may time delayed},
pages = {1633--1685},
title = {{Transfer Learning for Reinforcement Learning Domains : A Survey}},
url = {http://portal.acm.org/citation.cfm?id=1755839},
volume = {10},
year = {2009}
}
@article{Pfeiffer2003,
author = {Pfeiffer, F and Loffler, K and Gienger, M},
journal = {Proceedings of the sixth international conference of climbing and walking robots},
pages = {505--16},
title = {{Humanoid robots}},
year = {2003}
}
@misc{Arduino,
annote = {Data de consulta: 25 de febrer de 2014},
author = {Arduino},
keywords = {Arduino},
title = {{Arduino - HomePage}},
url = {http://www.arduino.cc/},
urldate = {10/03/14}
}
@article{Stulp2011,
author = {Stulp, Freek and Theodorou, Evangelos},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stulp, Theodorou - 2011 - Learning motion primitive goals for robust manipulation.pdf:pdf},
journal = {\ldots Robots and Systems \ldots},
number = {Section IV},
pages = {1--7},
title = {{Learning motion primitive goals for robust manipulation}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6094877},
volume = {2},
year = {2011}
}
@article{Fujita2000,
author = {Fujita, Masahiro},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fujita - 2000 - Digital creatures for future entertainment robotics.pdf:pdf},
isbn = {0780358864},
journal = {Robotics and Automation, 2000. Proceedings. ICRA' \ldots},
number = {April},
title = {{Digital creatures for future entertainment robotics}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=844149},
year = {2000}
}
@misc{ASIMO_History,
annote = {Data de consulta: 18 de mar\c{c} del 2014},
author = {HONDA},
title = {{History of ASIMO Robotics | ASIMO Innovations by Honda}},
url = {http://asimo.honda.com/asimo-history/},
urldate = {18/03/14}
}
@article{Orleans2004,
author = {Kaneko, K and Harada, K},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kaneko, Harada - 2008 - Humanoid robot HRP-3.pdf:pdf},
isbn = {0780382323},
journal = {Intelligent Robots \ldots},
number = {April},
title = {{Humanoid robot HRP-3}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4650604},
year = {2008}
}
@article{Hennig2011,
archivePrefix = {arXiv},
arxivId = {arXiv:1106.0800v3},
author = {Hennig, Philipp},
eprint = {arXiv:1106.0800v3},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hennig - 2011 - Optimal Reinforcement Learning for Gaussian Systems.0800v3:0800v3},
journal = {NIPS},
pages = {1--9},
title = {{Optimal Reinforcement Learning for Gaussian Systems.}},
url = {https://papers.nips.cc/paper/4410-optimal-reinforcement-learning-for-gaussian-systems.pdf},
year = {2011}
}
@inproceedings{Mutlu2006,
abstract = {Recent developments in humanoid robotics have made possible a vision of robots in everyday use in the home and workplace. However, little is known about how we should design social interactions with humanoid robots. We explored how cooperation versus competition in a game shaped people's perceptions of ASIMO. We found that in the co-operative interaction, people found the robot more sociable and more intellectual than in the competitive interaction while people felt more positive and were more involved in the task in the competitive condition than in the co-operative condition. Our poster presents these findings with the supporting theoretical background.},
author = {Mutlu, Bilge and Osman, S. and Forlizzi, Jodi and Hodgins, J. and Kiesler, S.},
booktitle = {Proceedings of the 1st ACM SIGCHI/SIGART conference on Human-robot interaction},
doi = {10.1145/1121241.1121311},
isbn = {1595932941},
keywords = {asimo,co-operation vs,competition,human-robot interaction,humanoid robots,robots,social,social perception},
pages = {351--352},
publisher = {ACM},
title = {{Perceptions of ASIMO: an exploration on co-operation and competition with humans and humanoid robots}},
url = {http://portal.acm.org/citation.cfm?id=1121311},
year = {2006}
}
@article{Hugel1999,
author = {Hugel, Vincent and Blazevic, P},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hugel, Blazevic - 1999 - Towards efficient implementation of quadruped gaits with duty factor of 0.75.pdf:pdf},
journal = {Robotics and Automation, 1999. \ldots},
number = {May},
title = {{Towards efficient implementation of quadruped gaits with duty factor of 0.75}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=770458},
year = {1999}
}
@book{Nguyen-Tuong2011,
abstract = {Models are among the most essential tools in robotics, such as kinematics and dynamics models of the robot's own body and controllable external objects. It is widely believed that intelligent mammals also rely on internal models in order to generate their actions. However, while classical robotics relies on manually generated models that are based on human insights into physics, future autonomous, cognitive robots need to be able to automatically generate models that are based on information which is extracted from the data streams accessible to the robot. In this paper, we survey the progress in model learning with a strong focus on robot control on a kinematic as well as dynamical level. Here, a model describes essential information about the behavior of the environment and the influence of an agent on this environment. In the context of model-based learning control, we view the model from three different perspectives. First, we need to study the different possible model learning architectures for robotics. Second, we discuss what kind of problems these architecture and the domain of robotics imply for the applicable learning methods. From this discussion, we deduce future directions of real-time learning algorithms. Third, we show where these scenarios have been used successfully in several case studies.},
author = {Nguyen-Tuong, Duy and Peters, Jan},
booktitle = {Cognitive processing},
doi = {10.1007/s10339-011-0404-1},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nguyen-Tuong, Peters - 2011 - Model learning for robot control a survey.pdf:pdf},
isbn = {3405062780},
issn = {1612-4790},
keywords = {Algorithms,Artificial Intelligence,Humans,Learning,Learning: physiology,Models, Psychological,Problem Solving,Robotics},
month = nov,
number = {4},
pages = {319--40},
pmid = {21487784},
title = {{Model learning for robot control: a survey.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21487784},
volume = {12},
year = {2011}
}
@article{Makimoto2002,
author = {Makimoto, Tsugio},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Makimoto - 2002 - Chip technologies for entertainment robots-present and future.pdf:pdf},
isbn = {0780374622},
journal = {Electron Devices Meeting, 2002. IEDM'02. \ldots},
pages = {1--8},
title = {{Chip technologies for entertainment robots-present and future}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1175768},
year = {2002}
}
@article{Marc2008,
author = {Marc, Raibert},
doi = {10.3182/20080706-5-KR-1001.01833},
editor = {Myung, Chung},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Marc - 200 - BigDog, the Rough-Terrain Quadruped Robot.pdf:pdf},
isbn = {9781123478},
month = jul,
pages = {10822--1085},
title = {{BigDog, the Rough-Terrain Quadruped Robot}},
url = {http://www.ifac-papersonline.net/Detailed/37519.html},
year = {200}
}
@article{Caruana2006,
abstract = {A number of supervised learning methods have been introduced in the last decade. Unfortunately, the last comprehensive empirical evaluation of supervised learning was the Statlog Project in the early 90's. We present a large-scale empirical comparison between ten supervised learning methods: SVMs, neural nets, logistic regression, naive bayes, memory-based learning, random forests, decision trees, bagged trees, boosted trees, and boosted stumps. We also examine the effect that calibrating the models via Platt Scaling and Isotonic Regression has on their performance. An important aspect of our study is the use of a variety of performance criteria to evaluate the learning methods.},
author = {Caruana, Rich and Niculescu-Mizil, Alexandru},
doi = {10.1145/1143844.1143865},
institution = {ACM},
isbn = {1595933832},
issn = {1595933832},
journal = {Proceedings of the 23rd international conference on Machine learning ICML 06},
number = {1},
pages = {161--168},
publisher = {ACM Press},
series = {ICML '06},
title = {{An empirical comparison of supervised learning algorithms}},
url = {http://portal.acm.org/citation.cfm?doid=1143844.1143865},
volume = {C},
year = {2006}
}
@phdthesis{Learned-Miller2014,
author = {Learned-Miller, Erik G.},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Learned-Miller - 2014 - Introduction to Supervised Learning.pdf:pdf},
pages = {1--5},
school = {University of Massachusetts, Amherst},
title = {{Introduction to Supervised Learning}},
url = {http://people.cs.umass.edu/~elm/Teaching/Docs/supervised2014a.pdf},
year = {2014}
}
@article{Nagasaka2004,
author = {Nagasaka, K and Kuroki, Y and Suzuki, S},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nagasaka, Kuroki, Suzuki - 2004 - Integrated motion control for walking, jumping and running on a small bipedal entertainment robot.pdf:pdf},
isbn = {0780382323},
journal = {Robotics and \ldots},
pages = {3189--3194},
title = {{Integrated motion control for walking, jumping and running on a small bipedal entertainment robot}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1308745},
year = {2004}
}
@article{Borovac2011,
author = {Borovac, Branislav and Nikoli\'{c}, M and Rakovi\'{c}, M},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Borovac, Nikoli\'{c}, Rakovi\'{c} - 2011 - Disturbance compensation of standing humanoid robot-simulation.pdf:pdf},
journal = {Proceedings of the XV \ldots},
keywords = {dynamic balance,humanoid robot,large disturbances,robot simulation},
title = {{Disturbance compensation of standing humanoid robot-simulation}},
url = {http://books.google.com/books?hl=en\&lr=\&id=McuBgVbfmx0C\&oi=fnd\&pg=PA83\&dq=Disturbance+Compensation+of+Standing+Humanoid+Robot+-+Simulation\&ots=7MySUZHSxT\&sig=LNzuPynKjtR-6Ss-xCzuzi1-szA},
year = {2011}
}
@techreport{ISO_Robot,
address = {Gen\`{e}ve},
author = {{International Organization for Standaritzacion}},
institution = {ISO},
title = {{ISO 8373:2012: Robots and robotic devices — Vocabulary}},
year = {2012}
}
@phdthesis{Xavier2010,
author = {P\'{e}rez, Xavier and Angulo, Cecilio and Escalera, Sergio},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/P\'{e}rez, Angulo, Escalera - 2010 - Vision-based Navigation and Reinforcement Learning Path Finding for Social Robots.pdf:pdf},
school = {Universitat Polit\'{e}cnica de Catalunya},
title = {{Vision-based Navigation and Reinforcement Learning Path Finding for Social Robots}},
url = {http://link.springer.com/chapter/10.1007/11780519\_16},
year = {2010}
}
@article{Tellez2005a,
author = {T\'{e}llez, RA A and Angulo, Cecilio and Pardo, DE E},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/T\'{e}llez, Angulo, Pardo - 2005 - Highly modular architecture for the general control of autonomous robots.pdf:pdf},
journal = {Computational Intelligence and \ldots},
number = {Figure 1},
pages = {709--716},
title = {{Highly modular architecture for the general control of autonomous robots}},
url = {http://link.springer.com/chapter/10.1007/11494669\_87},
year = {2005}
}
@article{Ion,
author = {Ion, Ion and Simionescu, Ion and Ungureanu, Marius},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ion, Simionescu, Ungureanu - Unknown - Stability Analysis of Gaits of Quadruped Walking Robot MERO.pdf:pdf},
journal = {\ldots Workshop on Mobile Robots, \ldots},
title = {{Stability Analysis of Gaits of Quadruped Walking Robot MERO}},
url = {http://www.profesaulosuna.com/data/files/ROBOTICA/ROBOT/20.pdf}
}
@article{Tellez2005a,
author = {T\'{e}llez, RA and Angulo, Cecilio and Pardo, DE},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/T\'{e}llez, Angulo, Pardo - 2005 - Highly modular architecture for the general control of autonomous robots.pdf:pdf},
journal = {Computational Intelligence and \ldots},
pages = {709--716},
title = {{Highly modular architecture for the general control of autonomous robots}},
url = {http://link.springer.com/chapter/10.1007/11494669\_87},
year = {2005}
}
@misc{Lauszus2012,
annote = {Data de consulta: 10/6/2014},
author = {Lauszus, Kristian},
title = {{KalmanFilter - TKJElectronics}},
url = {https://github.com/TKJElectronics/KalmanFilter},
year = {2012}
}
@article{Zhang2007,
author = {Zhang, Jiaqi and Chen, Qijun},
doi = {10.1109/CEC.2007.4424653},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Chen - 2007 - Learning based gaits evolution for an AIBO dog.pdf:pdf},
isbn = {978-1-4244-1339-3},
journal = {2007 IEEE Congress on Evolutionary Computation},
month = sep,
pages = {1523--1526},
publisher = {Ieee},
title = {{Learning based gaits evolution for an AIBO dog}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4424653},
year = {2007}
}
@article{Delphinanto2011,
abstract = {Prioritization of flows in a home network based on traffic classification is still no guarantee that enough bandwidth will be available between a server and a client. Besides, such QoS technologies need to be supported by every device in the end-to-end path to be effective, which is relatively expensive for the owners of home networks. In any small-scale IP network (best-effort or QoS-enabled) it is therefore preferable to diagnose the network in real time, before admitting a new flow. In this paper we demonstrate a new method to probe the available bandwidth between a server and a client in an IP-based home network. The tool works with existing end-user devices, is non-intrusive, has a short measurement time, does not require pre-knowledge of the link layer network topology, and is accurate enough to make decisions about the admission of high-throughput high-quality streams such as for IPTV services.},
author = {Delphinanto, Archi and Koonen, Ton and den Hartog, Frank},
doi = {10.1109/CCNC.2011.5766506},
institution = {Electrical Engineering Department, Eindhoven University of Technology, Eindhoven, The Netherlands},
isbn = {978-1-4244-8788-2},
journal = {2011 IEEE Consumer Communications and Networking Conference (CCNC)},
pages = {431--435},
publisher = {IEEE},
title = {{End-to-end available bandwidth probing in heterogeneous IP home networks}},
year = {2011}
}
@article{TFG_Carlos_Ramos,
author = {{Ramos Olave}, Carlos Mario},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ramos Olave - 2013 - Dise\~{n}o, implementaci\'{o}n y control visual de posici\'{o}n de un sistema placa-bola.pdf:pdf},
institution = {Universitat Polit\'{e}cnica de Catalunya},
title = {{Dise\~{n}o, implementaci\'{o}n y control visual de posici\'{o}n de un sistema placa-bola}},
year = {2013}
}
@misc{Khatib2002,
abstract = {As applications of robots extend into everyday human life, new approaches to simulating interactions between them and their environments are emerging at the intersection of the physical and virtual worlds.},
author = {Khatib, Oussama and Brock, Oliver and Chang, Kyong-Sok and Conti, Francois and Ruspini, Diego and Sentis, Luis},
booktitle = {Communications of the ACM},
doi = {10.1145/504729.504753},
issn = {00010782},
title = {{Robotics and interactive simulation}},
volume = {45},
year = {2002}
}
@misc{ROS,
annote = {Data de consulta: 22 de febrer de 2014},
author = {{Robot Operating System}},
keywords = {ROS},
title = {{ROS.org}},
url = {http://www.ros.org/core-components/},
urldate = {10/03/14}
}
@article{Loffler2003,
author = {Loffler, K. and Gienger, M. and Pfeiffer, F.},
doi = {10.1177/0278364903022003007},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Loffler, Gienger, Pfeiffer - 2003 - Sensors and Control Concept of Walking Johnnie.pdf:pdf},
issn = {0278-3649},
journal = {The International Journal of Robotics Research},
keywords = {biped robot,control,dynamic sta-,sensors},
month = mar,
number = {3-4},
pages = {229--239},
title = {{Sensors and Control Concept of Walking "Johnnie"}},
url = {http://ijr.sagepub.com/cgi/doi/10.1177/0278364903022003007},
volume = {22},
year = {2003}
}
@article{Singh,
author = {Singh, G. and a.Y. Ng},
doi = {10.1109/ROBOT.2006.1642158},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Singh, Ng - Unknown - Quadruped robot obstacle negotiation via reinforcement learning.pdf:pdf},
isbn = {0-7803-9505-0},
journal = {Proceedings 2006 IEEE International Conference on Robotics and Automation, 2006. ICRA 2006.},
pages = {3003--3010},
publisher = {Ieee},
title = {{Quadruped robot obstacle negotiation via reinforcement learning}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1642158}
}
@article{Anshar2007,
author = {Anshar, Muh. and Williams, Mary-Anne},
doi = {10.1016/S1672-6529(07)60039-0},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Anshar, Williams - 2007 - Extended Evolutionary Fast Learn-to-Walk Approach for Four-Legged Robots.pdf:pdf},
issn = {16726529},
journal = {Journal of Bionic Engineering},
keywords = {2007,all rights reserved,and science press,convergence,copyright,genetic,jilin university,learning,legged-robots,locomotion,published by elsevier limited,walking gaits},
month = dec,
number = {4},
pages = {255--263},
title = {{Extended Evolutionary Fast Learn-to-Walk Approach for Four-Legged Robots}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1672652907600390},
volume = {4},
year = {2007}
}
@article{Ignell,
author = {Ignell, NB and Rasmusson, Niclas and Matsson, Johan},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ignell, Rasmusson, Matsson - Unknown - An overview of legged and wheeled robotic locomotion.pdf:pdf},
journal = {idt.mdh.se},
keywords = {continuous tracks,ity,legged robot,legs,mobil-,robot,wheeled robot,wheels},
title = {{An overview of legged and wheeled robotic locomotion.}},
url = {http://www.idt.mdh.se/kurser/ct3340/ht12/MINICONFERENCE/FinalPapers/ircse12\_submission\_21.pdf}
}
@article{Gaydou2011,
author = {Gaydou, David and Redolfi, J and Henze, A},
file = {:media/Datos/Lluis/Documents/Industrials/8e Quatrimestre/Treball Final de Grau/Bibliografia/Articles/Filtro complementario para estimaci\'{o}n de actitud aplicado al controlador embebido de un cuatrirrotor.pdf:pdf},
journal = {\ldots de Sist. Embebidos},
title = {{Filtro complementario para estimacion de actitud aplicado al controlador embebido de un cuatrirrotor}},
url = {http://proyectos.ciii.frc.utn.edu.ar/cuadricoptero/export/9ed95816c90cc7d83e32fd2e13b032dc515c0d7a/documentacion/informe\_final/paper\_case.pdf},
year = {2011}
}
@article{Peula2009,
author = {Peula, Jose Manuel and Urdiales, Cristina and Herrero, Ignacio and S\'{a}nchez-Tato, Isabel and Sandoval, Francisco},
doi = {10.1016/j.robot.2008.11.003},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Peula et al. - 2009 - Pure reactive behavior learning using Case Based Reasoning for a vision based 4-legged robot.pdf:pdf},
issn = {09218890},
journal = {Robotics and Autonomous Systems},
month = jun,
number = {6-7},
pages = {688--699},
publisher = {Elsevier B.V.},
title = {{Pure reactive behavior learning using Case Based Reasoning for a vision based 4-legged robot}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0921889008002066},
volume = {57},
year = {2009}
}
@article{Argall2009,
author = {Argall, Brenna D. and Chernova, Sonia and Veloso, Manuela and Browning, Brett},
doi = {10.1016/j.robot.2008.10.024},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Argall et al. - 2009 - A survey of robot learning from demonstration.pdf:pdf},
issn = {09218890},
journal = {Robotics and Autonomous Systems},
keywords = {learning from demonstration},
month = may,
number = {5},
pages = {469--483},
publisher = {Elsevier B.V.},
title = {{A survey of robot learning from demonstration}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0921889008001772},
volume = {57},
year = {2009}
}
@article{Rico2004,
author = {Rico, FM and Gonz\'{a}lez-Careaga, R},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rico, Gonz\'{a}lez-Careaga - 2004 - Programming model based on concurrent objects for the AIBO robot.pdf:pdf},
journal = {Universidad Rey Juan \ldots},
title = {{Programming model based on concurrent objects for the AIBO robot}},
url = {http://133.11.9.3/~takeo/course/2006/media/papers/aibo\_concurrencia04.pdf},
year = {2004}
}
@article{Hohl2006,
author = {Hohl, Lukas and Tellez, Ricardo and Michel, Olivier and Ijspeert, Auke Jan},
doi = {10.1016/j.robot.2006.02.006},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hohl et al. - 2006 - Aibo and Webots Simulation, wireless remote control and controller transfer.pdf:pdf},
issn = {09218890},
journal = {Robotics and Autonomous Systems},
keywords = {aibo,cross-compilation,remote control,robot simulation,webots},
month = jun,
number = {6},
pages = {472--485},
title = {{Aibo and Webots: Simulation, wireless remote control and controller transfer}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0921889006000327},
volume = {54},
year = {2006}
}
@phdthesis{Kniewasser,
author = {Kniewasser, Gerhard},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kniewasser - Unknown - Reinforcement Learning with Dynamic Movement Primitives-DMPs.pdf:pdf},
pages = {1--5},
school = {University of Technology},
title = {{Reinforcement Learning with Dynamic Movement Primitives-DMPs}},
url = {http://www.igi.tugraz.at/rueckert/Projects/Masterprojekt\_kniewasser\_final1-1.pdf}
}
@article{Kober2009,
author = {Kober, Jens and Peters, Jan},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kober, Peters - 2012 - Reinforcement learning in robotics A survey.pdf:pdf},
journal = {Reinforcement Learning},
keywords = {learning control,reinforcement learning},
title = {{Reinforcement learning in robotics: A survey}},
url = {http://link.springer.com/chapter/10.1007/978-3-642-27645-3\_18},
year = {2012}
}
@misc{iec-dlc,
annote = {Data de consulta: 30 de mar\c{c} del 2014},
author = {d'Estudis Catalans, Institut},
title = {{Diccionari de la llengua catalana}},
url = {http://dlc.iec.cat/index.html}
}
@article{Wawrzynski2012,
author = {Wawrzyński, Paweł},
doi = {10.1016/j.procs.2012.09.130},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wawrzyński - 2012 - Autonomous Reinforcement Learning with Experience Replay for Humanoid Gait Optimization.pdf:pdf},
issn = {18770509},
journal = {Procedia Computer Science},
keywords = {autonomous learning,learning in robots,reinforcement learning},
month = jan,
pages = {205--211},
title = {{Autonomous Reinforcement Learning with Experience Replay for Humanoid Gait Optimization}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1877050912007375},
volume = {13},
year = {2012}
}
@article{Ruckert2013,
abstract = {A salient feature of human motor skill learning is the ability to exploit similarities across related tasks. In biological motor control, it has been hypothesized that muscle synergies, coherent activations of groups of muscles, allow for exploiting shared knowledge. Recent studies have shown that a rich set of complex motor skills can be generated by a combination of a small number of muscle synergies. In robotics, dynamic movement primitives are commonly used for motor skill learning. This machine learning approach implements a stable attractor system that facilitates learning and it can be used in high-dimensional continuous spaces. However, it does not allow for reusing shared knowledge, i.e., for each task an individual set of parameters has to be learned. We propose a novel movement primitive representation that employs parametrized basis functions, which combines the benefits of muscle synergies and dynamic movement primitives. For each task a superposition of synergies modulates a stable attractor system. This approach leads to a compact representation of multiple motor skills and at the same time enables efficient learning in high-dimensional continuous systems. The movement representation supports discrete and rhythmic movements and in particular includes the dynamic movement primitive approach as a special case. We demonstrate the feasibility of the movement representation in three multi-task learning simulated scenarios. First, the characteristics of the proposed representation are illustrated in a point-mass task. Second, in complex humanoid walking experiments, multiple walking patterns with different step heights are learned robustly and efficiently. Finally, in a multi-directional reaching task simulated with a musculoskeletal model of the human arm, we show how the proposed movement primitives can be used to learn appropriate muscle excitation patterns and to generalize effectively to new reaching skills.},
author = {R\"{u}ckert, Elmar and D'Avella, Andrea},
doi = {10.3389/fncom.2013.00138},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/R\"{u}ckert, d'Avella - 2013 - Learned parametrized dynamic movement primitives with shared synergies for controlling robotic and musculosk.pdf:pdf},
issn = {1662-5188},
journal = {Frontiers in computational neuroscience},
keywords = {dynamic movement primitives,dynamic movement primitives, muscle synergies, rei,motor control,muscle synergies,musculoskeletal model,reinforcement learning},
month = jan,
number = {October},
pages = {138},
pmid = {24146647},
title = {{Learned parametrized dynamic movement primitives with shared synergies for controlling robotic and musculoskeletal systems.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3797962\&tool=pmcentrez\&rendertype=abstract},
volume = {7},
year = {2013}
}
@article{Sutton1998,
abstract = {In which we tru to give a basic intuitive sense of what reinforcement learning is and how it differs and relates to other fields, e.g., supervised learning and neural networks, genetic algorithms and artificial life, control theory. Intuituvely, Rl is trial and error (variation and selection, search) plus learning (association, memory). We argue that RL is the only field that seriously addresses the special features of the problem of learning from interaction to achieve long-term goals.},
author = {Sutton, R S and Barto, A G},
doi = {10.1109/TNN.1998.712192},
isbn = {0262193981},
issn = {1045-9227},
journal = {IEEE transactions on neural networks / a publication of the IEEE Neural Networks Council},
pages = {1054},
pmid = {18255791},
title = {{Reinforcement learning: an introduction.}},
volume = {9},
year = {1998}
}
@article{Albiez2003,
author = {Albiez, J.C. and Luksch, T. and Berns, K. and Dillmann, R.},
doi = {10.1016/S0921-8890(03)00068-X},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Albiez et al. - 2003 - Reactive reflex-based control for a four-legged walking machine.pdf:pdf},
issn = {09218890},
journal = {Robotics and Autonomous Systems},
keywords = {adaptive control,behaviour control,biological inspired robots,walking machines},
month = sep,
number = {3-4},
pages = {181--189},
title = {{Reactive reflex-based control for a four-legged walking machine}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S092188900300068X},
volume = {44},
year = {2003}
}
@article{Pastor2009,
author = {Pastor, Peter and Hoffmann, Heiko and Asfour, Tamim and Schaal, Stefan},
doi = {10.1109/ROBOT.2009.5152385},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pastor et al. - 2009 - Learning and generalization of motor skills by learning from demonstration.pdf:pdf},
isbn = {978-1-4244-2788-8},
journal = {2009 IEEE International Conference on Robotics and Automation},
month = may,
pages = {763--768},
publisher = {Ieee},
title = {{Learning and generalization of motor skills by learning from demonstration}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5152385},
year = {2009}
}
@article{Chestnutt2005,
abstract = {  Despite the recent achievements in stable dynamic walking for many humanoid robots, relatively little navigation autonomy has been achieved. In particular, the ability to autonomously select foot placement positions to avoid obstacles while walking is an important step towards improved navigation autonomy for humanoids. We present a footstep planner for the Honda ASIMO humanoid robot that plans a sequence of footstep positions to navigate toward a goal location while avoiding obstacles. The possible future foot placement positions are dependent on the current state of the robot. Using a finite set of state-dependent actions, we use an A* search to compute optimal sequences of footstep locations up to a time-limited planning horizon. We present experimental results demonstrating the robot navigating through both static and dynamic known environments that include obstacles moving on predictable trajectories. },
author = {Chestnutt, J. and Lau, M. and Cheung, G. and Kuffner, J. and Hodgins, J. and Kanade, T.},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chestnutt et al. - 2005 - Footstep Planning for the Honda ASIMO Humanoid.pdf:pdf},
journal = {Proceedings of the 2005 IEEE International Conference on Robotics and Automation},
keywords = {Humanoid robots,biped locomotion,footstep planning,obstacle avoidance},
title = {{Footstep Planning for the Honda ASIMO Humanoid}},
year = {2005}
}
@misc{Robotics,
annote = {Data de consulta: 20 de mar\c{c} del 2014},
author = {Robotics, PAL},
title = {{REEM-C | PAL Robotics Blog}},
url = {http://blog.pal-robotics.com/blog/2013/11/21/unplug-play-reem-c/},
urldate = {20/03/14}
}
@article{Tellez2006,
author = {T\'{e}llez, RA and Angulo, Cecilio and Pardo, DE},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/T\'{e}llez, Angulo, Pardo - 2006 - Evolving the walking behaviour of a 12 dof quadruped using a distributed neural architecture.pdf:pdf},
journal = {Biologically Inspired Approaches to \ldots},
title = {{Evolving the walking behaviour of a 12 dof quadruped using a distributed neural architecture}},
url = {http://link.springer.com/chapter/10.1007/11613022\_4},
year = {2006}
}
@article{Bie,
author = {Bie, Stefan and Persson, Johan},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bie, Persson - 2004 - Behavior-based Control of the ERS-7 AIBO Robot.pdf:pdf},
title = {{Behavior-based Control of the ERS-7 AIBO Robot}},
url = {http://fileadmin.cs.lth.se/ai/xj/StefanBie/report.pdf},
year = {2004}
}
@article{Vukobratovic2004,
author = {Vukobratovi\'{c}, M and Borovac, Branislav},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vukobratovi\'{c}, Borovac - 2004 - Zero-moment point—thirty five years of its life.pdf:pdf},
journal = {International Journal of Humanoid \ldots},
keywords = {biped locomotion,dynamically balanced gait,support,zero-moment point},
number = {1},
pages = {157--173},
title = {{Zero-moment point—thirty five years of its life}},
url = {http://www.worldscientific.com/doi/abs/10.1142/S0219843604000083},
volume = {1},
year = {2004}
}
@article{Michel2004,
abstract = {Cyberbotics Ltd. develops WebotsTM, a mobile robotics simulation software that provides you with a rapid prototyping environment for modelling, programming and simulating mobile robots. The provided robot libraries enable you to transfer your control programs to several commercially available real mobile robots. WebotsTM lets you define and modify a complete mobile robotics setup, even several different robots sharing the same environment. For each object, you can define a number of properties, such as shape, color, texture, mass, friction, etc. You can equip each robot with a large number of available sensors and actuators. You can program these robots using your favorite development environment, simulate them and optionally transfer the resulting programs onto your real robots. WebotsTM has been developed in collaboration with the Swiss Federal Institute of Technology in Lausanne, thoroughly tested, well documented and continuously maintained for over 7 years. It is now the main commercial product available from Cyberbotics Ltd.},
archivePrefix = {arXiv},
arxivId = {cs/0412052},
author = {Michel, Olivier},
eprint = {0412052},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Michel, Michel - 2004 - Cyberbotics Ltd. Webots Professional Mobile Robot Simulation.pdf:pdf},
journal = {International Journal of Advanced Robotic Systems},
keywords = {commercial software,mobile robot simulation,rapid prototyping,transfer to real robots,webots tm},
pages = {40--43},
primaryClass = {cs},
title = {{Cyberbotics Ltd. Webots: Professional Mobile Robot Simulation}},
volume = {1},
year = {2004}
}
@phdthesis{Pfeiffer2014,
author = {Pfeiffer, Sammy},
file = {:media/Datos/Lluis/Documents/Industrials/8e Quatrimestre/Treball Final de Grau/Bibliografia/PFCs referencia/Gesture learning and generation and execution of slightly modified gestures
.pdf:pdf},
number = {January},
school = {Universitat Polit\`{e}cnica de Catalunya},
title = {{Gesture learning and generation and execution of slightly modified gestures}},
year = {2014}
}
@article{Hornby2000,
author = {Hornby, GS and Takamura, S},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hornby, Takamura - 2000 - Evolving robust gaits with AIBO.pdf:pdf},
journal = {\ldots . ICRA'00. IEEE \ldots},
title = {{Evolving robust gaits with AIBO}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=846489},
year = {2000}
}
@article{Makimoto2002,
author = {Makimoto, Tsugio},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Makimoto - 2002 - Chip technologies for entertainment robots-present and future.pdf:pdf},
isbn = {0780374622},
journal = {Electron Devices Meeting, 2002. IEDM'02. \ldots},
pages = {1--8},
title = {{Chip technologies for entertainment robots-present and future}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1175768},
year = {2002}
}
@phdthesis{Menendez2011,
author = {{Men\'{e}ndez Paredes}, R},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Men\'{e}ndez Paredes - 2011 - Control y supervisi\'{o}n inal\'{a}mbrica de la plataforma rob\'{o}tica Pleo.pdf:pdf},
school = {Universitat Polit\'{e}cnica de Catalunya},
title = {{Control y supervisi\'{o}n inal\'{a}mbrica de la plataforma rob\'{o}tica Pleo}},
url = {http://upcommons.upc.edu/handle/2099.1/11801},
year = {2011}
}
@article{Raibert2008,
abstract = {Less than half the Earth's landmass is accessible to existing wheeled and tracked vehicles. But people and animals using their legs can go almost anywhere on Earth. Our mission at Boston Dynamics is to develop a new breed of rough-terrain robots that capture the mobility, autonomy and speed of living creatures. Such robots will travel in outdoor terrain that is too steep, rutted, rocky, wet, muddy, and snowy for conventional vehicles. They will also travel in cities and in our homes, doing chores and providing care, where steps, stairways and household clutter limit the utility of wheeled vehicles. Robots meeting these goals will have terrain sensors, sophisticated computing and power systems, advanced actuators and dynamic controls. I will give a status report on BigDog, an example of such rough-terrain robots. It is a 100 kg quadruped robot that balances actively as it operates on a variety of outdoor terrains, carries a 65 kg load, runs travels at up to 11 kph.},
author = {Raibert, Marc and Blankespoor, Kevin},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Raibert, Blankespoor - 2008 - Bigdog, the rough-terrain quadruped robot.pdf:pdf},
journal = {Proceedings of the 17th IFAC World Congress},
keywords = {bigdog},
title = {{Bigdog, the rough-terrain quadruped robot}},
url = {http://web.unair.ac.id/admin/file/f\_7773\_bigdog.pdf},
year = {2008}
}
@article{Zhou2004,
author = {Zhou, C and Yue, PK and Ni, J and Chan, SB},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhou et al. - 2004 - Dynamically stable gait planning for a humanoid robot to climb sloping surface.pdf:pdf},
isbn = {0780386450},
journal = {Robotics, Automation and \ldots},
keywords = {-biped gait,climbing slope,dynamic walk,humanoid robots,point,stability of walking,zero moment},
pages = {1--3},
title = {{Dynamically stable gait planning for a humanoid robot to climb sloping surface}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1438942},
year = {2004}
}
@misc{REEM_C,
annote = {Data de consulta: 18 de mar\c{c} de 2014},
author = {Robotics, PAL},
title = {{REEM-C}},
url = {http://pal-robotics.com/en/robots/reem-c},
urldate = {18/03/14}
}
@misc{Rowberg,
annote = {Data de consulta: 10/6/2014},
author = {Rowberg, Jeff},
title = {{I2C Device Library}},
url = {http://www.i2cdevlib.com/},
urldate = {10/06/14}
}
@incollection{Shadmehr2004,
annote = {Data de consulta: 11 de juny de 2014},
author = {Shadmehr, R and Wise, S. P.},
booktitle = {Computational Neurobiology of Reaching and Pointing},
title = {{Minimum Jerk Trajectory}},
url = {http://www.shadmehrlab.org/book/minimum\_jerk/minimumjerk.htm},
year = {2004}
}
@article{Loc2010,
author = {Loc, Vo-Gia and Roh, Se-goh and Koo, Ig Mo and Tran, Duc Trong and Kim, Ho Moon and Moon, Hyungpil and Choi, Hyouk Ryeol},
doi = {10.1016/j.robot.2009.11.007},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Loc et al. - 2010 - Sensing and gait planning of quadruped walking and climbing robot for traversing in complex environment.pdf:pdf},
issn = {09218890},
journal = {Robotics and Autonomous Systems},
month = may,
number = {5},
pages = {666--675},
publisher = {Elsevier B.V.},
title = {{Sensing and gait planning of quadruped walking and climbing robot for traversing in complex environment}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0921889009002048},
volume = {58},
year = {2010}
}
@misc{Aibo_Images,
annote = {Data de consulta: 8 de mar\c{c} de 2014},
author = {Rainsersen},
keywords = {Rainsersen},
title = {{Imatges Aibo ERS-7}},
url = {http://rainersen.de/aibo/},
urldate = {10/03/14}
}
@article{Santos2011,
author = {Santos, Cristina P. and Matos, V\'{\i}tor},
doi = {10.1016/j.robot.2011.05.003},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Santos, Matos - 2011 - Gait transition and modulation in a quadruped robot A brainstem-like modulation approach.pdf:pdf},
issn = {09218890},
journal = {Robotics and Autonomous Systems},
month = sep,
number = {9},
pages = {620--634},
publisher = {Elsevier B.V.},
title = {{Gait transition and modulation in a quadruped robot: A brainstem-like modulation approach}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0921889011000789},
volume = {59},
year = {2011}
}
@phdthesis{Cano2013,
author = {Ca\~{n}o, A Fern\'{a}ndez},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ca\~{n}o - 2013 - Dise\~{n}o e implementaci\'{o}n de sistemas de control de tiempo real mediante herramientas de generaci\'{o}n autom\'{a}tica de c\'{o}di.pdf:pdf},
school = {Universitat Polit\'{e}cnica de Catalunya},
title = {{Dise\~{n}o e implementaci\'{o}n de sistemas de control de tiempo real mediante herramientas de generaci\'{o}n autom\'{a}tica de c\'{o}digo}},
url = {http://upcommons.upc.edu/pfc/handle/2099.1/19455},
year = {2013}
}
@article{Hirai1998,
author = {Hirai, Kazuo},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hirai - 1998 - Current and future perspective of Honda humanoid robot.pdf:pdf},
journal = {Robotics Research},
title = {{Current and future perspective of Honda humanoid robot}},
url = {http://link.springer.com/chapter/10.1007/978-1-4471-1580-9\_44},
year = {1998}
}
@article{Hirai1998,
author = {Hirai, Kazuo},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hirai - 1998 - Current and future perspective of Honda humanoid robot.pdf:pdf},
journal = {Robotics Research},
title = {{Current and future perspective of Honda humanoid robot}},
url = {http://link.springer.com/chapter/10.1007/978-1-4471-1580-9\_44},
year = {1998}
}
@book{Alpaydin2004,
abstract = {The goal of machine learning is to program computers to use example data or past experience to solve a given problem. Many successful applications of machine learning exist already, including systems that analyze past sales data to predict customer behavior, recognize faces or spoken speech, optimize robot behavior so that a task can be completed using minimum resources, and extract knowledge from bioinformatics data. Introduction to Machine Learning is a comprehensive textbook on the subject, covering a broad array of topics not usually included in introductory machine learning texts. It discusses many methods based in different fields, including statistics, pattern recognition, neural networks, artificial intelligence, signal processing, control, and data mining, in order to present a unified treatment of machine learning problems and solutions. All learning algorithms are explained so that the student can easily move from the equations in the book to a computer program. The book can be used by advanced undergraduates and graduate students who have completed courses in computer programming, probability, calculus, and linear algebra. It will also be of interest to engineers in the field who are concerned with the application of machine learning methods.<br <br After an introduction that defines machine learning and gives examples of machine learning applications, the book covers supervised learning, Bayesian decision theory, parametric methods, multivariate methods, dimensionality reduction, clustering, nonparametric methods, decision trees, linear discrimination, multilayer perceptrons, local models, hidden Markov models, assessing and comparing classification algorithms, combining multiple learners, and reinforcement learning.},
author = {Alpaydin, Ethem},
booktitle = {Machine Learning},
doi = {10.1007/s10994-009-5137-3},
isbn = {0262012111},
issn = {08856125},
pages = {233--237},
title = {{Introduction to Machine Learning (Adaptive Computation and Machine Learning)}},
url = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0262012111},
volume = {5},
year = {2004}
}
@article{Schaal2010,
abstract = {With the goal to generate more scalable algorithms with higher efficiency and fewer open parameters, reinforcement learning (RL) has recently moved towards combining classical techniques from optimal control and dynamic programming with modern learning techniques from statistical estimation theory. In this vein, this paper suggests to use the framework of stochastic optimal control with path integrals to derive a novel approach to RL with parameterized policies. While solidly grounded in value function estimation and optimal control based on the stochastic Hamilton-Jacobi-Bellman (HJB) equations, policy improvements can be transformed into an approximation problem of a path integral which has no open algorithmic parameters other than the exploration noise. The resulting algorithm can be conceived of as model-based, semi-model-based, or even model free, depending on how the learning problem is structured. The update equations have no danger of numerical instabilities as neither matrix inversions nor gradient learning rates are required. Our new algorithm demonstrates interesting similarities with previous RL research in the framework of probability matching and provides intuition why the slightly heuristically motivated probability matching approach can actually perform well. Empirical evaluations demonstrate significant performance improvements over gradient-based policy learning and scalability to high-dimensional control problems. Finally, a learning experiment on a simulated 12 degree-of-freedom robot dog illustrates the functionality of our algorithm in a complex robot learning scenario. We believe that Policy Improvement with Path Integrals (PI2) offers currently one of the most efficient, numerically robust, and easy to implement algorithms for RL based on trajectory roll-outs.},
author = {Schaal, Stefan},
file = {:media/Datos/Lluis/Documents/Industrials/8e Quatrimestre/Treball Final de Grau/Bibliografia/Articles/A Generalized Path Integral Control Approach to Reinforcement Learning
.pdf:pdf},
isbn = {1532-4435},
issn = {15324435},
journal = {Journal of Machine Learning Research},
keywords = {parameterized policies,reinforcement learning,stochastic optimal control},
pages = {3137--3181},
title = {{A Generalized Path Integral Control Approach to Reinforcement Learning}},
url = {http://dl.acm.org/citation.cfm?id=1953033},
volume = {11},
year = {2010}
}
@article{Or2010,
abstract = {Biped humanoid robots have gained much popularity in recent years. These robots are mainly controlled by two major control methods, the biologically-inspired approach based on Central Pattern Generator (CPG) and the engineering-oriented approach based on Zero Moment Point (ZMP). Given that flexibility in the body torso is required in some human activities, we believe that it is beneficial for the next generation of humanoid robots to have a flexible spine as humans do. In order to cope with the increased complexity in controlling this type of robot, a new kind of control system is necessary. Currently, there is no controller that allows a flexible spine humanoid robot to maintain stability in real-time while walking with dynamic spine motions. This paper presents a new hybrid CPG-ZMP control system for the walking of a realistically simulated flexible spine humanoid robot. Experimental results showed that using our control method, the robot is able to adapt its spine motions in real-time to allow stable walking. Our control system could be used for the control of the next generation humanoid robots.},
author = {Or, Jimmy},
doi = {10.1016/j.neunet.2009.11.003},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Or - 2010 - A hybrid CPG-ZMP control system for stable walking of a simulated flexible spine humanoid robot.pdf:pdf},
issn = {1879-2782},
journal = {Neural networks : the official journal of the International Neural Network Society},
keywords = {Computer Simulation,Elasticity,Humans,Motion,Motor Neurons,Motor Neurons: physiology,Neural Networks (Computer),Neurons,Neurons: physiology,Periodicity,Robotics,Robotics: methods,Spine,Spine: physiology,Walking,Walking: physiology},
month = apr,
number = {3},
pages = {452--60},
pmid = {20031370},
publisher = {Elsevier Ltd},
title = {{A hybrid CPG-ZMP control system for stable walking of a simulated flexible spine humanoid robot.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20031370},
volume = {23},
year = {2010}
}
@article{Kertesz2013,
author = {Kert\'{e}sz, Csaba},
doi = {10.9781/ijimai.2013.237},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kert\'{e}sz - 2013 - Improvements in the native development environment for Sony AIBO.pdf:pdf},
issn = {1989-1660},
journal = {International Journal of Interactive Multimedia and Artificial Intelligence},
keywords = {aibo,aperios,open-r,sdk,toolchain,urbi},
number = {3},
pages = {51},
title = {{Improvements in the native development environment for Sony AIBO}},
url = {http://www.ijimai.org/journal/node/500},
volume = {2},
year = {2013}
}
@article{Lee1988,
author = {Lee, TT and Liao, CM and Chen, TK},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lee, Liao, Chen - 1988 - On the stability properties of hexapod tripod gait.pdf:pdf},
journal = {Robotics and Automation, IEEE \ldots},
number = {4},
title = {{On the stability properties of hexapod tripod gait}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=808},
volume = {4},
year = {1988}
}
@article{Park2007,
author = {Park, IW and Kim, JY and Lee, Jungho},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Park, Kim, Lee - 2007 - Development of biped humanoid robots at the humanoid robot research center, korea advanced institute of science.pdf:pdf},
isbn = {9783902613073},
journal = {Humanoid Robots– \ldots},
number = {June},
title = {{Development of biped humanoid robots at the humanoid robot research center, korea advanced institute of science and technology (KAIST)}},
url = {http://cdn.intechopen.com/pdfs/161.pdf},
year = {2007}
}
@misc{Urbi_Docs,
annote = {Data de consulta: 6 de mar\c{c} de 2014},
author = {Gostai},
keywords = {Gostai},
title = {{URBI Doc for Aibo ERS2xx ERS7 and URBI 1.0}},
url = {http://www.gostai.com/doc/en/aibo/},
urldate = {10/03/14}
}
@article{Fujita2000,
author = {Fujita, Masahiro},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fujita - 2000 - Digital creatures for future entertainment robotics.pdf:pdf},
isbn = {0780358864},
journal = {Robotics and Automation, 2000. Proceedings. ICRA' \ldots},
number = {April},
title = {{Digital creatures for future entertainment robotics}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=844149},
year = {2000}
}
@article{Borovac2011a,
author = {Borovac, Branislav and Nikoli\'{c}, M and Rakovi\'{c}, M},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Borovac, Nikoli\'{c}, Rakovi\'{c} - 2011 - Disturbance compensation of standing humanoid robot-theory.pdf:pdf},
journal = {Int. ScientiŊc Conf. Industrial \ldots},
keywords = {dynamic balance,humanoid robot,large disturbances,standing posture},
title = {{Disturbance compensation of standing humanoid robot-theory}},
url = {http://books.google.com/books?hl=en\&lr=\&id=McuBgVbfmx0C\&oi=fnd\&pg=PA90\&dq=Disturbance+Compensation+of+Standing+Humanoid+Robot+\%E2\%80\%93+Theory\&ots=7MySUZHTqW\&sig=mIK2l\_ztRNAdIWoH\_x6mqA0PmjU},
year = {2011}
}
@book{Cord2008,
author = {Cord, Matthieu and Cunningham, P\'{a}draig},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cord, Cunningham - 2008 - Machine learning techniques for multimedia.pdf:pdf},
title = {{Machine learning techniques for multimedia}},
url = {ftp://icksie.no-ip.org/EBooks/Computers/Artificial Intelligence/Semi-supervised learning.pdf ftp://icksie.no-ip.org/EBooks/Computers/Artificial Intelligence/Cord\_Cunningham-Machine\_Learning\_Techniques\_for\_Multimedia-9783540751700.pdf},
year = {2008}
}
@phdthesis{Kolovrat2013,
author = {Kolovrat, Stipe},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kolovrat - 2013 - Development of Android Application for Sony Aibo ERS-7 robot.pdf:pdf},
school = {Universitat Polit\`{e}cnica de Catalunya},
title = {{Development of Android Application for Sony Aibo ERS-7 robot}},
year = {2013}
}
@article{Sancho2011,
author = {Sancho, Marina Zapater},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sancho - 2011 - An\'{a}lisis y dise\~{n}o de un robot m\'{o}vil aut\'{o}nomo y de su localizaci\'{o}n e integraci\'{o}n en un ambiente inteligente.pdf:pdf},
title = {{An\'{a}lisis y dise\~{n}o de un robot m\'{o}vil aut\'{o}nomo y de su localizaci\'{o}n e integraci\'{o}n en un ambiente inteligente}},
url = {http://upcommons.upc.edu/handle/2099.1/9778},
year = {2011}
}
@article{Lin2001,
author = {Lin, BS and Song, SM},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lin, Song - 2001 - Dynamic modeling, stability, and energy efficiency of a quadrupedal walking machine.pdf:pdf},
journal = {Journal of Robotic Systems},
title = {{Dynamic modeling, stability, and energy efficiency of a quadrupedal walking machine}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/rob.8104/abstract},
year = {2001}
}
@article{B2012,
author = {B, Amir Massah and K., Arman Sharifi and Salehinia, Yaser and Najafi, Farid},
doi = {10.1016/j.proeng.2012.07.176},
file = {:home/lluis/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/B et al. - 2012 - An Open Loop Walking on Different Slopes for NAO Humanoid Robot.pdf:pdf},
issn = {18777058},
journal = {Procedia Engineering},
keywords = {humanoid robot,nao,trajectory planning,zmp},
month = jan,
number = {Iris},
pages = {296--304},
title = {{An Open Loop Walking on Different Slopes for NAO Humanoid Robot}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1877705812025623},
volume = {41},
year = {2012}
}
